{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/data/hotel/pos_count_dict.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corenlpsf import StanfordNLP\n",
    "from sklearn.externals import joblib\n",
    "from collections import defaultdict, Counter\n",
    "sNLP = StanfordNLP()\n",
    "def countpos(filenames):\n",
    "    pos_count = Counter()\n",
    "    pos_dict = defaultdict(list)\n",
    "    for fname in filenames:\n",
    "        with open(fname, \"r\") as f:\n",
    "            for line in f:\n",
    "                wds, pos = zip(*sNLP.pos(line.strip()))\n",
    "                pos_count[str(pos)] += 1\n",
    "                pos_dict[str(pos)].extend([\" \".join(wds)])\n",
    "    return pos_dict, pos_count\n",
    "fname = \"/media/data/hotel/kdd_merge_posneg.txt\"\n",
    "pos_dict, pos_count = countpos([fname])\n",
    "joblib.dump([pos_count,pos_dict], \"/media/data/hotel/pos_count_dict.pkl\")\n",
    "# filenames = ['/media/data/booking.com/booking.negative.sorted.tkn.txt', '/media/data/booking.com/booking.positive.sorted.tkn.txt']\n",
    "# pos_dict, pos_count = countpos(filenames)\n",
    "# joblib.dump([pos_count,pos_dict], \"/media/data/booking.com/pos_count_dict.pkl\")\n",
    "# pos_count,pos_dict = joblib.load(\"/media/data/booking.com/pos_count_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"('JJ', 'NN', '.')\", 1637),\n",
       " (\"('DT', 'NN', 'VBD', 'JJ', '.')\", 579),\n",
       " (\"('PRP', 'MD', 'RB', 'VB', 'RB', 'RB', '.')\", 566),\n",
       " (\"('RB', 'JJ', '.')\", 498),\n",
       " (\"('RB', 'VBN', '.')\", 459),\n",
       " (\"('RB', 'JJ', 'NN', '.')\", 441),\n",
       " (\"('NNP', 'NN', '.')\", 428),\n",
       " (\"('MD', 'RB', 'VB', 'RB', 'RB', '.')\", 364),\n",
       " (\"('DT', 'NN', 'VBZ', 'JJ', '.')\", 362),\n",
       " (\"('NN', 'VBD', 'JJ', '.')\", 310)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I will never stay here again .',\n",
       " 'I will never stay there again .',\n",
       " 'I will never stay here again .',\n",
       " 'I will never stay here again .',\n",
       " 'I would never stay here again !',\n",
       " 'I would not stay there again .',\n",
       " 'I would never stay there again .',\n",
       " 'I would not stay there again .',\n",
       " 'I would never stay there again .',\n",
       " 'I will not stay there again .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict[\"('PRP', 'MD', 'RB', 'VB', 'RB', 'RB', '.')\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from six import iteritems\n",
    "\n",
    "    \n",
    "class MyData(object):\n",
    "    def __init__(self, filenames):\n",
    "        self.filenames = filenames\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for fname in self.filenames:\n",
    "            with open(fname, \"r\") as f:\n",
    "                for line in f:\n",
    "                    yield line.strip().lower().split()\n",
    "       \n",
    "    \n",
    "filenames = ['/media/data/booking.com/booking.negative.sorted.tkn.txt', \n",
    "             '/media/data/booking.com/booking.positive.sorted.tkn.txt']\n",
    "stoplist = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \n",
    "            \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \n",
    "            \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\",\n",
    "            \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
    "            \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "            \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \n",
    "            \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "            \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \n",
    "            \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\",\n",
    "            \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \n",
    "            \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \n",
    "            \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "\n",
    "corpus = MyData(filenames)   \n",
    "dictionary = corpora.Dictionary(sent for sent in corpus)\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids)  # remove stop words and words that appear only once\n",
    "dictionary.compactify()\n",
    "dictionary.save('/tmp/booking.dictionary.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __init__(self, dictionary, corpus):\n",
    "        self.dictionary = dictionary\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for sent in self.corpus:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield self.dictionary.doc2bow(sent)\n",
    "            \n",
    "bowvecs = []\n",
    "vecgen = MyCorpus(dictionary, corpus)\n",
    "for vec in vecgen:\n",
    "    bowvecs.append(vec)\n",
    "corpora.MmCorpus.serialize('/tmp/booking.corpus.mm', bowvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models, similarities\n",
    "tfidf = models.TfidfModel(bowvecs) # step 1 -- initialize a model\n",
    "corpus_tfidf = tfidf[bowvecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(733, 1), (1998, 1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowvecs[109090]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spa'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.get(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.02218453380358644), (1, 0.8372404062115201), (2, 0.54638479908091)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.02218453380358644), (1, 0.8372404062115201), (2, 0.54638479908091)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[[(0, 1), (1, 1), (2, 1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(53, 0.09042548516812363),\n",
       " (69, 0.1971464786545802),\n",
       " (1234, 0.9761949075805552)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[dictionary.doc2bow(\"awesome room food awesome awesome awesome\".split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
